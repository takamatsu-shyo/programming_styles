{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "kEIle9IkyWxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys, os, string, random"
      ],
      "metadata": {
        "id": "zOViJSHCyisG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = string.printable\n",
        "char_indices = dict((c, i) for i, c in enumerate(characters))\n",
        "indices_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "S4tQCcIQyz56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VOCAB_SIZE = len(characters)\n",
        "WINDOW_SIZE = 3"
      ],
      "metadata": {
        "id": "qn5ArGvXzQ0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_one_hot(line):\n",
        "  line = \" \" + line + \" \"\n",
        "  x = np.zeros((len(line), INPUT_VOCAB_SIZE))\n",
        "  for i, c in enumerate(line):\n",
        "    index = char_indices[c] if c in characters else char_indices[' ']\n",
        "    x[i][index] = 1\n",
        "  return x"
      ],
      "metadata": {
        "id": "5NiXikfmzB_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_one_hot(x):\n",
        "  s = []\n",
        "  for onehot in x:\n",
        "    one_index = np.argmax(onehot)\n",
        "    s.append(indices_char[one_index])\n",
        "  return ''.join(s)"
      ],
      "metadata": {
        "id": "gOLpK_XY0Ir4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_for_window(x):\n",
        "  ind = [np.array(np.arange(i, i+WINDOW_SIZE)) for i in range(x.shape[0] - WINDOW_SIZE + 1)]\n",
        "  ind = np.array(ind, dtype=np.int32)\n",
        "  x_window = x[ind]\n",
        "  return x_window.reshape(x_window.shape[0], x_window.shape[1]*x_window.shape[2])"
      ],
      "metadata": {
        "id": "YK-ngRtS0s1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization_layer_set_weights(n_layer):\n",
        "  wb = []\n",
        "  w = np.zeros((WINDOW_SIZE*INPUT_VOCAB_SIZE, INPUT_VOCAB_SIZE))\n",
        "  b = np.zeros((INPUT_VOCAB_SIZE))\n",
        "\n",
        "  for c in string.ascii_lowercase:\n",
        "    i = char_indices[c]\n",
        "    w[INPUT_VOCAB_SIZE+i, i] = 1\n",
        "\n",
        "  for c in string.ascii_uppercase:\n",
        "    i = char_indices[c]\n",
        "    il = char_indices[c.lower()]\n",
        "    w[INPUT_VOCAB_SIZE+i, il] = 1\n",
        "\n",
        "  sp_idx = char_indices[' ']\n",
        "  non_letters = [c for c in list(characters) if c not in list(string.ascii_letters)]\n",
        "\n",
        "  for c in non_letters:\n",
        "    i = char_indices[c]\n",
        "    w[INPUT_VOCAB_SIZE+i, sp_idx] = 1\n",
        "\n",
        "  for c in non_letters:\n",
        "    i = char_indices[c]\n",
        "    w[i, sp_idx] = 0.75\n",
        "    w[INPUT_VOCAB_SIZE*2+i, sp_idx] = 0.75\n",
        "\n",
        "  wb.append(w)\n",
        "  wb.append(b)\n",
        "  n_layer.set_weights(wb)\n",
        "  return n_layer"
      ],
      "metadata": {
        "id": "kuDWKJpZ15R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(INPUT_VOCAB_SIZE,\n",
        "                  input_shape=(WINDOW_SIZE*INPUT_VOCAB_SIZE,),\n",
        "                  activation='softmax'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "_XZbM-PWlYC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "63V6h0vN2XWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21mrA_ot2Y7i",
        "outputId": "3357a423-d254-427a-fe31-90c5cfc19a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30100 (117.58 KB)\n",
            "Trainable params: 30100 (117.58 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer_set_weights(model.layers[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoVkGSxF2bsX",
        "outputId": "2e2ebc71-4126-44fa-d6d9-4b21a945b292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.dense.Dense at 0x7a26dd01f9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.gutenberg.org/cache/epub/46144/pg46144.txt"
      ],
      "metadata": {
        "id": "hPXUuYZp2fNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a113390-1f30-412e-8f76-b284050542d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-31 17:42:32--  https://www.gutenberg.org/cache/epub/46144/pg46144.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125798 (123K) [text/plain]\n",
            "Saving to: ‘pg46144.txt.2’\n",
            "\n",
            "pg46144.txt.2       100%[===================>] 122.85K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-03-31 17:42:32 (1.73 MB/s) - ‘pg46144.txt.2’ saved [125798/125798]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head pg46144.txt > pg46144_head.txt"
      ],
      "metadata": {
        "id": "jNfsh8EE-ilI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('pg46144_head.txt') as f:\n",
        "  for line in f:\n",
        "    if line.isspace(): continue\n",
        "    batch = prepare_for_window(encode_one_hot(line))\n",
        "    preds = model.predict(batch)\n",
        "    normal = decode_one_hot(preds)\n",
        "    print(normal, \" /// \",line)"
      ],
      "metadata": {
        "id": "yQ4dpLvW9zct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc64ba4-d7f6-40ac-d843-af5892723dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            " the project gutenberg ebook of six cups of coffee   ///  ﻿The Project Gutenberg eBook of Six Cups of Coffee\n",
            "\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "this ebook is for the use of anyone anywhere in the united states and   ///  This ebook is for the use of anyone anywhere in the United States and\n",
            "\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "most other parts of the world at no cost and with almost no restrictions   ///  most other parts of the world at no cost and with almost no restrictions\n",
            "\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "whatsoever  you may copy it  give it away or re use it under the terms   ///  whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "of the project gutenberg license included with this ebook or online   ///  of the Project Gutenberg License included with this ebook or online\n",
            "\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "at www gutenberg org  if you are not located in the united states    ///  at www.gutenberg.org. If you are not located in the United States,\n",
            "\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "you will have to check the laws of the country where you are located   ///  you will have to check the laws of the country where you are located\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "before using this ebook    ///  before using this eBook.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}